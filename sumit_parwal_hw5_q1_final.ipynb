{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "INF-552                                      \n",
    "Sumit Parwal \n",
    "ID-5174593050\n",
    "Assignment-5\n",
    "Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import hamming_loss\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import collections\n",
    "from imblearn import under_sampling, over_sampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datastet Features: (7195, 22)\n",
      "Datastet classes: (7195, 3)\n"
     ]
    }
   ],
   "source": [
    "filename = \"Frogs_MFCCs.csv\"\n",
    "data_set = pd.read_csv(filename)\n",
    "X = data_set.iloc[:, :22]\n",
    "y = data_set.iloc[:, 22:25]\n",
    "y_fam = data_set['Family']\n",
    "y_gen = data_set['Genus']\n",
    "y_spe = data_set['Species']\n",
    "print(\"Datastet Features:\",X.shape)\n",
    "print(\"Datastet classes:\",y.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a) Splitting between test and train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train dataset features: (5036, 22)\n",
      "Train label: (5036, 3)\n",
      "Test dataset features: (2159, 22)\n",
      "Test label: (2159, 3)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "         X, y, test_size=0.3, random_state=42)\n",
    "# print(y)\n",
    "print(\"Train dataset features:\",X_train.shape)\n",
    "print(\"Train label:\",y_train.shape)\n",
    "print(\"Test dataset features:\",X_test.shape)\n",
    "print(\"Test label:\",y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b)i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Exact match is used to indicate the percentage of samples that have all their labels classified correctly and is considerd as most strict meteric\n",
    "\n",
    "Hamming Loss is the fraction of the wrong labels to the total number of labels.\n",
    "\n",
    "Both this methods are used to evaluate Multi-label Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b)ii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_ExactMatch(y_predict, y_test):\n",
    "    exact_MatchList = list()\n",
    "    for i in range(len(y_test)):\n",
    "        if set(y_predict.values[i,:]) == set(y_test.iloc[i,:]):\n",
    "            exact_MatchList.append(1)\n",
    "        else:\n",
    "            exact_MatchList.append(0)\n",
    "    return sum(exact_MatchList) / len(exact_MatchList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluation_HammingLoss(y_predict, y_test):\n",
    "    hamming_LossList = list()\n",
    "    for i in range(len(y_test)):\n",
    "         hamming_LossList.append(hamming_loss(y_predict.iloc[i,:], y_test.iloc[i,:]))\n",
    "    return sum( hamming_LossList) / len( hamming_LossList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Raw Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model for 'Species' label: GridSearchCV(cv=10, error_score='raise-deprecating',\n",
      "             estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "                           decision_function_shape='ovr', degree=3,\n",
      "                           gamma='auto_deprecated', kernel='rbf', max_iter=-1,\n",
      "                           probability=False, random_state=None, shrinking=True,\n",
      "                           tol=0.001, verbose=False),\n",
      "             iid='warn', n_jobs=None,\n",
      "             param_grid={'C': array([1.00000000e-03, 1.77827941e-01, 3.16227766e+01, 5.62341325e+03,\n",
      "       1.00000000e+06]),\n",
      "                         'gamma': array([0.1  , 0.575, 1.05 , 1.525, 2.   ])},\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
      "             scoring=None, verbose=0)\n",
      "Best parameter values for 'Species' Label: {'C': 31.622776601683793, 'gamma': 1.525}\n",
      "CV Score with best parameter values for 'Species' Label: 0.9906671961874504\n"
     ]
    }
   ],
   "source": [
    "# Species\n",
    "params_dict = {\"C\": np.logspace(-3, 6, 5), \"gamma\": np.linspace(0.1, 2, 5)}\n",
    "svm = SVC(kernel=\"rbf\")\n",
    "\n",
    "s = GridSearchCV(estimator=svm, param_grid=params_dict, cv=10)\n",
    "s.fit(X_train,y_train['Species'])   \n",
    "\n",
    "species_Label_bestparams =s.best_params_\n",
    "species_Label_bestscore= s.best_score_\n",
    "species_Label_bestmodel = s\n",
    "print(\"best model for 'Species' label:\",species_Label_bestmodel)\n",
    "print(\"Best parameter values for 'Species' Label:\", species_Label_bestparams)\n",
    "print(\"CV Score with best parameter values for 'Species' Label:\", species_Label_bestscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model for 'Species' label: GridSearchCV(cv=10, error_score='raise-deprecating',\n",
      "             estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "                           decision_function_shape='ovr', degree=3,\n",
      "                           gamma='auto_deprecated', kernel='rbf', max_iter=-1,\n",
      "                           probability=False, random_state=None, shrinking=True,\n",
      "                           tol=0.001, verbose=False),\n",
      "             iid='warn', n_jobs=None,\n",
      "             param_grid={'C': array([1.00000000e-03, 1.77827941e-01, 3.16227766e+01, 5.62341325e+03,\n",
      "       1.00000000e+06]),\n",
      "                         'gamma': array([0.1  , 0.575, 1.05 , 1.525, 2.   ])},\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
      "             scoring=None, verbose=0)\n",
      "Best parameter values for 'Genus' Label: {'C': 31.622776601683793, 'gamma': 1.525}\n",
      "CV Score with best parameter values for 'Genus' Label: 0.9910643367752184\n"
     ]
    }
   ],
   "source": [
    "# Genus\n",
    "params_dict = {\"C\": np.logspace(-3, 6, 5), \"gamma\": np.linspace(0.1, 2, 5)}\n",
    "svm = SVC(kernel=\"rbf\")\n",
    "\n",
    "s = GridSearchCV(estimator=svm, param_grid=params_dict, cv=10)\n",
    "s.fit(X_train,y_train['Genus'])   \n",
    "\n",
    "Gen_Label_bestparams =s.best_params_\n",
    "Gen_Label_bestscore= s.best_score_\n",
    "Gen_Label_bestmodel = s\n",
    "\n",
    "print(\"best model for 'Species' label:\",Gen_Label_bestmodel)\n",
    "print(\"Best parameter values for 'Genus' Label:\", Gen_Label_bestparams)\n",
    "print(\"CV Score with best parameter values for 'Genus' Label:\", Gen_Label_bestscore)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best model for 'Species' label: GridSearchCV(cv=10, error_score='raise-deprecating',\n",
      "             estimator=SVC(C=1.0, cache_size=200, class_weight=None, coef0=0.0,\n",
      "                           decision_function_shape='ovr', degree=3,\n",
      "                           gamma='auto_deprecated', kernel='rbf', max_iter=-1,\n",
      "                           probability=False, random_state=None, shrinking=True,\n",
      "                           tol=0.001, verbose=False),\n",
      "             iid='warn', n_jobs=None,\n",
      "             param_grid={'C': array([1.00000000e-03, 1.77827941e-01, 3.16227766e+01, 5.62341325e+03,\n",
      "       1.00000000e+06]),\n",
      "                         'gamma': array([0.1  , 0.575, 1.05 , 1.525, 2.   ])},\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
      "             scoring=None, verbose=0)\n",
      "Best parameter values for 'Family' Label: {'C': 31.622776601683793, 'gamma': 2.0}\n",
      "CV Score with best parameter values for 'Family' Label: 0.9932486100079428\n"
     ]
    }
   ],
   "source": [
    "# Family\n",
    "params_dict = {\"C\": np.logspace(-3, 6, 5), \"gamma\": np.linspace(0.1, 2, 5)}\n",
    "svm = SVC(kernel=\"rbf\")\n",
    "\n",
    "s = GridSearchCV(estimator=svm, param_grid=params_dict, cv=10)\n",
    "s.fit(X_train,y_train['Family'])   \n",
    "\n",
    "fam_Label_bestparams =s.best_params_\n",
    "fam_Label_bestscore= s.best_score_\n",
    "fam_Label_bestmodel = s\n",
    "\n",
    "print(\"best model for 'Species' label:\",fam_Label_bestmodel)\n",
    "# fam_Label_bestparams, fam_Label_bestscore, fam_Label_bestmodel = svmclassifier_gaussian(X_train, y_train['Family'])\n",
    "\n",
    "print(\"Best parameter values for 'Family' Label:\", fam_Label_bestparams)\n",
    "print(\"CV Score with best parameter values for 'Family' Label:\", fam_Label_bestscore)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "afer getting best parrameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Family\n",
    "svm = SVC(kernel=\"rbf\", C=fam_Label_bestparams['C'], gamma=fam_Label_bestparams['gamma'])\n",
    "svm.fit(X_train, y_train['Family'],)   \n",
    "y_p_fam = svm.predict(X_test)\n",
    "y_p_fam = pd.DataFrame(y_p_fam)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genus\n",
    "svm = SVC(kernel=\"rbf\", C=Gen_Label_bestparams['C'], gamma=Gen_Label_bestparams['gamma'])\n",
    "svm.fit(X_train, y_train['Genus'],)   \n",
    "y_p_gen = svm.predict(X_test)\n",
    "y_p_gen = pd.DataFrame(y_p_gen)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Species\n",
    "svm = SVC(kernel=\"rbf\", C=species_Label_bestparams['C'], gamma=species_Label_bestparams['gamma'])\n",
    "svm.fit(X_train, y_train['Species'],)   \n",
    "y_p_spe = svm.predict(X_test)\n",
    "y_p_spe = pd.DataFrame(y_p_spe)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine\n",
    "y_predict = pd.concat([y_p_fam, y_p_gen, y_p_spe], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating Hamiing loss and Exact MAtch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming loss for Gaussian Kernel:  0.007410838351088467\n",
      "Exact Match Score for Gaussian Kernel:  0.9898100972672533\n"
     ]
    }
   ],
   "source": [
    "hamming_Loss = evaluation_HammingLoss(y_predict, y_test)       \n",
    "exactmatch_Score = evaluation_ExactMatch(y_predict, y_test)\n",
    "\n",
    "print('Hamming loss for Gaussian Kernel: ', hamming_Loss)\n",
    "print('Exact Match Score for Gaussian Kernel: ', exactmatch_Score)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b)iii)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5036, 22)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "x = X_train.values #returns a numpy array\n",
    "scaler = StandardScaler()\n",
    "x_scaled = scaler.fit_transform(x)\n",
    "X_train_stand = pd.DataFrame(x_scaled)\n",
    "X_train_stand.shape\n",
    "# X_train_stand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2159, 22)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = X_test.values #returns a numpy array\n",
    "scaler = StandardScaler()\n",
    "x_scaled = scaler.fit_transform(x)\n",
    "X_test_stand= pd.DataFrame(x_scaled)\n",
    "X_test_stand.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svmclassifier_L1(X_train, y_train):\n",
    "    params_dict = {\"C\": np.logspace(-3, 6, 10)}\n",
    "    svm = LinearSVC(penalty='l1', dual=False)\n",
    "    s = GridSearchCV(estimator=svm, param_grid=params_dict, cv=10)\n",
    "    s.fit(X_train, y_train)   \n",
    "#     print(\"Best parameter values:\", s.best_params_)\n",
    "#     print(\"CV Score with best parameter values:\", s.best_score_)\n",
    "    return s.best_params_, s.best_score_, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svmclassifier_L1_best(X_train, y_train, C_, X_test):\n",
    "    svm = LinearSVC(penalty='l1', dual=False, C=C_)\n",
    "    svm.fit(X_train, y_train)   \n",
    "    y_predict = svm.predict(X_test)\n",
    "    return y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model for 'Family' Label: GridSearchCV(cv=10, error_score='raise-deprecating',\n",
      "             estimator=LinearSVC(C=1.0, class_weight=None, dual=False,\n",
      "                                 fit_intercept=True, intercept_scaling=1,\n",
      "                                 loss='squared_hinge', max_iter=1000,\n",
      "                                 multi_class='ovr', penalty='l1',\n",
      "                                 random_state=None, tol=0.0001, verbose=0),\n",
      "             iid='warn', n_jobs=None,\n",
      "             param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03, 1.e+04,\n",
      "       1.e+05, 1.e+06])},\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
      "             scoring=None, verbose=0)\n",
      "Best parameter values for 'Family' Label: {'C': 1.0}\n",
      "CV Score with best parameter values for 'Family' Label: 0.9406274821286735\n"
     ]
    }
   ],
   "source": [
    "# Family\n",
    "params_dict = {\"C\": np.logspace(-3, 6, 10)}\n",
    "svm = LinearSVC(penalty='l1', dual=False)\n",
    "s = GridSearchCV(estimator=svm, param_grid=params_dict, cv=10)\n",
    "s.fit(X_train_stand, y_train['Family'])  \n",
    "fam_Label_bestparams_L1 =s.best_params_\n",
    "fam_Label_bestscore_L1 = s.best_score_\n",
    "fam_Label_bestmodel_L1 = s\n",
    "\n",
    "print(\"Best Model for 'Family' Label:\", fam_Label_bestmodel_L1)\n",
    "print(\"Best parameter values for 'Family' Label:\", fam_Label_bestparams_L1)\n",
    "print(\"CV Score with best parameter values for 'Family' Label:\", fam_Label_bestscore_L1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model for 'Family' Label: GridSearchCV(cv=10, error_score='raise-deprecating',\n",
      "             estimator=LinearSVC(C=1.0, class_weight=None, dual=False,\n",
      "                                 fit_intercept=True, intercept_scaling=1,\n",
      "                                 loss='squared_hinge', max_iter=1000,\n",
      "                                 multi_class='ovr', penalty='l1',\n",
      "                                 random_state=None, tol=0.0001, verbose=0),\n",
      "             iid='warn', n_jobs=None,\n",
      "             param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03, 1.e+04,\n",
      "       1.e+05, 1.e+06])},\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
      "             scoring=None, verbose=0)\n",
      "Best parameter values for 'Genus' Label: {'C': 100.0}\n",
      "CV Score with best parameter values for 'Genus' Label: 0.9529388403494837\n"
     ]
    }
   ],
   "source": [
    "# Genus\n",
    "params_dict = {\"C\": np.logspace(-3, 6, 10)}\n",
    "svm = LinearSVC(penalty='l1', dual=False)\n",
    "s = GridSearchCV(estimator=svm, param_grid=params_dict, cv=10)\n",
    "s.fit(X_train_stand, y_train['Genus'])  \n",
    "Gen_Label_bestparams_L1 =s.best_params_\n",
    "Gen_Label_bestscore_L1 = s.best_score_\n",
    "Gen_Label_bestmodel_L1 = s\n",
    "\n",
    "print(\"Best Model for 'Family' Label:\", Gen_Label_bestmodel_L1)\n",
    "print(\"Best parameter values for 'Genus' Label:\", Gen_Label_bestparams_L1)\n",
    "print(\"CV Score with best parameter values for 'Genus' Label:\", Gen_Label_bestscore_L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model for 'Family' Label: GridSearchCV(cv=10, error_score='raise-deprecating',\n",
      "             estimator=LinearSVC(C=1.0, class_weight=None, dual=False,\n",
      "                                 fit_intercept=True, intercept_scaling=1,\n",
      "                                 loss='squared_hinge', max_iter=1000,\n",
      "                                 multi_class='ovr', penalty='l1',\n",
      "                                 random_state=None, tol=0.0001, verbose=0),\n",
      "             iid='warn', n_jobs=None,\n",
      "             param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03, 1.e+04,\n",
      "       1.e+05, 1.e+06])},\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
      "             scoring=None, verbose=0)\n",
      "Best parameter values for 'Species' Label: {'C': 1.0}\n",
      "CV Score with best parameter values for 'Species' Label: 0.9606830818109611\n"
     ]
    }
   ],
   "source": [
    "# Species\n",
    "params_dict = {\"C\": np.logspace(-3, 6, 10)}\n",
    "svm = LinearSVC(penalty='l1', dual=False)\n",
    "s = GridSearchCV(estimator=svm, param_grid=params_dict, cv=10)\n",
    "s.fit(X_train_stand, y_train['Species'])  \n",
    "species_Label_bestparams_L1 =s.best_params_\n",
    "species_Label_bestscore_L1 = s.best_score_\n",
    "species_Label_bestmodel_L1 = s\n",
    "\n",
    "print(\"Best Model for 'Family' Label:\", species_Label_bestmodel_L1)\n",
    "print(\"Best parameter values for 'Species' Label:\", species_Label_bestparams_L1)\n",
    "print(\"CV Score with best parameter values for 'Species' Label:\", species_Label_bestscore_L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Family\n",
    "svm = LinearSVC(penalty='l1', dual=False, C=fam_Label_bestparams_L1['C'])\n",
    "svm.fit(X_train_stand, y_train['Family'])   \n",
    "y_p_fam_L1 = svm.predict(X_test_stand)\n",
    "y_p_fam_L1 = pd.DataFrame(y_p_fam_L1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genus\n",
    "svm = LinearSVC(penalty='l1', dual=False, C=Gen_Label_bestparams_L1['C'])\n",
    "svm.fit(X_train_stand, y_train['Genus'])   \n",
    "y_p_gen_L1 = svm.predict(X_test_stand)\n",
    "y_p_gen_L1 = pd.DataFrame(y_p_gen_L1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Species\n",
    "svm = LinearSVC(penalty='l1', dual=False, C=species_Label_bestparams_L1['C'])\n",
    "svm.fit(X_train_stand, y_train['Species'])   \n",
    "y_p_spe_L1 = svm.predict(X_test_stand)\n",
    "y_p_spe_L1 = pd.DataFrame(y_p_spe_L1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine\n",
    "y_predict = pd.concat([y_p_fam_L1, y_p_gen_L1, y_p_spe_L1], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hamming loss for Gaussian Kernel:  0.05913231434306002\n",
      "Exact Match Score for Gaussian Kernel:  0.9092172301991662\n"
     ]
    }
   ],
   "source": [
    "hamming_Loss_1 = evaluation_HammingLoss(y_predict, y_test)       \n",
    "exactmatch_Score_1 = evaluation_ExactMatch(y_predict, y_test)\n",
    "\n",
    "print('Hamming loss for Gaussian Kernel: ', hamming_Loss_1)\n",
    "print('Exact Match Score for Gaussian Kernel: ', exactmatch_Score_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "b)iv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svmclassifier_L1_smote(X_train, y_train):\n",
    "    print('Original dataset shape {}'.format(collections.Counter(y_train))) \n",
    "    sm = SMOTE(random_state=42)\n",
    "    X_res, y_res = sm.fit_sample(X_train, y_train)    \n",
    "    print('Resampled dataset shape {}'.format(collections.Counter(y_res)))\n",
    "    params_dict = {\"C\": np.logspace(-3, 6, 10)}\n",
    "#     svm = SVC(kernel=\"rbf\")\n",
    "    svm = LinearSVC(penalty='l1', dual=False)\n",
    "    # grid search\n",
    "    s = GridSearchCV(estimator=svm, param_grid=params_dict, cv=10)\n",
    "    s.fit(X_res, y_res)   \n",
    "    return s.best_params_, s.best_score_, s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({'Leptodactylidae': 3073, 'Hylidae': 1542, 'Dendrobatidae': 380, 'Bufonidae': 41})\n",
      "Resampled dataset shape Counter({'Leptodactylidae': 3073, 'Dendrobatidae': 3073, 'Hylidae': 3073, 'Bufonidae': 3073})\n",
      "Model for 'Family' label: GridSearchCV(cv=10, error_score='raise-deprecating',\n",
      "             estimator=LinearSVC(C=1.0, class_weight=None, dual=False,\n",
      "                                 fit_intercept=True, intercept_scaling=1,\n",
      "                                 loss='squared_hinge', max_iter=1000,\n",
      "                                 multi_class='ovr', penalty='l1',\n",
      "                                 random_state=None, tol=0.0001, verbose=0),\n",
      "             iid='warn', n_jobs=None,\n",
      "             param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03, 1.e+04,\n",
      "       1.e+05, 1.e+06])},\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
      "             scoring=None, verbose=0)\n",
      "Best parameter  for 'Family' Labelvalues: {'C': 10.0}\n",
      "CV Score with best parameter for 'Family' Label values: 0.9511064106736089\n"
     ]
    }
   ],
   "source": [
    "fam_params_l1_rs, fam_score_l1_rs, fam_model_l1_rs = svmclassifier_L1_smote(X_train_stand, y_train['Family'])\n",
    "print(\"Model for 'Family' label:\",fam_model_l1_rs)\n",
    "print(\"Best parameter  for 'Family' Labelvalues:\", fam_params_l1_rs)\n",
    "print(\"CV Score with best parameter for 'Family' Label values:\",fam_score_l1_rs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({'Adenomera': 2899, 'Hypsiboas': 1125, 'Ameerega': 380, 'Dendropsophus': 226, 'Leptodactylus': 174, 'Scinax': 111, 'Osteocephalus': 80, 'Rhinella': 41})\n",
      "Resampled dataset shape Counter({'Adenomera': 2899, 'Ameerega': 2899, 'Hypsiboas': 2899, 'Rhinella': 2899, 'Scinax': 2899, 'Dendropsophus': 2899, 'Leptodactylus': 2899, 'Osteocephalus': 2899})\n",
      "Model for 'Genus' label: GridSearchCV(cv=10, error_score='raise-deprecating',\n",
      "             estimator=LinearSVC(C=1.0, class_weight=None, dual=False,\n",
      "                                 fit_intercept=True, intercept_scaling=1,\n",
      "                                 loss='squared_hinge', max_iter=1000,\n",
      "                                 multi_class='ovr', penalty='l1',\n",
      "                                 random_state=None, tol=0.0001, verbose=0),\n",
      "             iid='warn', n_jobs=None,\n",
      "             param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03, 1.e+04,\n",
      "       1.e+05, 1.e+06])},\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
      "             scoring=None, verbose=0)\n",
      "Best parameter  for 'Genus' Labelvalues: {'C': 10.0}\n",
      "CV Score with best parameter for 'Genus' Label values: 0.9604605036219386\n"
     ]
    }
   ],
   "source": [
    "# Genus\n",
    "\n",
    "Gen_params_l1_rs, Gen_score_l1_rs, Gen_model_l1_rs = svmclassifier_L1_smote(X_train_stand, y_train['Genus'])\n",
    "print(\"Model for 'Genus' label:\",Gen_model_l1_rs)\n",
    "print(\"Best parameter  for 'Genus' Labelvalues:\", Gen_params_l1_rs)\n",
    "print(\"CV Score with best parameter for 'Genus' Label values:\",Gen_score_l1_rs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dataset shape Counter({'AdenomeraHylaedactylus': 2447, 'HypsiboasCordobae': 788, 'AdenomeraAndre': 452, 'Ameeregatrivittata': 380, 'HypsiboasCinerascens': 337, 'HylaMinuta': 226, 'LeptodactylusFuscus': 174, 'ScinaxRuber': 111, 'OsteocephalusOophagus': 80, 'Rhinellagranulosa': 41})\n",
      "Resampled dataset shape Counter({'AdenomeraHylaedactylus': 2447, 'Ameeregatrivittata': 2447, 'HypsiboasCinerascens': 2447, 'AdenomeraAndre': 2447, 'Rhinellagranulosa': 2447, 'ScinaxRuber': 2447, 'HylaMinuta': 2447, 'HypsiboasCordobae': 2447, 'LeptodactylusFuscus': 2447, 'OsteocephalusOophagus': 2447})\n",
      "Model for 'Species' label: GridSearchCV(cv=10, error_score='raise-deprecating',\n",
      "             estimator=LinearSVC(C=1.0, class_weight=None, dual=False,\n",
      "                                 fit_intercept=True, intercept_scaling=1,\n",
      "                                 loss='squared_hinge', max_iter=1000,\n",
      "                                 multi_class='ovr', penalty='l1',\n",
      "                                 random_state=None, tol=0.0001, verbose=0),\n",
      "             iid='warn', n_jobs=None,\n",
      "             param_grid={'C': array([1.e-03, 1.e-02, 1.e-01, 1.e+00, 1.e+01, 1.e+02, 1.e+03, 1.e+04,\n",
      "       1.e+05, 1.e+06])},\n",
      "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
      "             scoring=None, verbose=0)\n",
      "Best parameter  for 'Species' Labelvalues: {'C': 100.0}\n",
      "CV Score with best parameter for 'Species' Label values: 0.9635472006538619\n"
     ]
    }
   ],
   "source": [
    "# Species\n",
    "Spe_params_l1_rs, Spe_score_l1_rs, Spe_model_l1_rs = svmclassifier_L1_smote(X_train_stand, y_train['Species'])\n",
    "print(\"Model for 'Species' label:\",Spe_model_l1_rs)\n",
    "print(\"Best parameter  for 'Species' Labelvalues:\", Spe_params_l1_rs)\n",
    "print(\"CV Score with best parameter for 'Species' Label values:\",Spe_score_l1_rs )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def svmclassifier_L1_smote_best(X_train, y_train, C_, X_test):\n",
    "    sm = SMOTE(random_state=42)\n",
    "    X_res, y_res = sm.fit_sample(X_train, y_train)   \n",
    "    svm = LinearSVC(penalty='l1', dual=False, C=C_)\n",
    "    svm.fit(X_train, y_train)   \n",
    "    y_predict = svm.predict(X_test)\n",
    "    return y_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Family\n",
    "y_p_fam_l1_rs = svmclassifier_L1_smote_best(X_train_stand, y_train['Family'], fam_params_l1_rs['C'], X_test_stand)\n",
    "y_p_fam_l1_rs = pd.DataFrame(y_p_fam_l1_rs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genus\n",
    "y_p_gen_l1_rs = svmclassifier_L1_smote_best(X_train_stand, y_train['Genus'], Gen_params_l1_rs['C'], X_test_stand)\n",
    "y_p_gen_l1_rs = pd.DataFrame(y_p_gen_l1_rs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Species\n",
    "y_p_spe_l1_rs = svmclassifier_L1_smote_best(X_train_stand, y_train['Species'], Spe_params_l1_rs['C'], X_test_stand)\n",
    "y_p_spe_l1_rs = pd.DataFrame(y_p_spe_l1_rs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# combine\n",
    "y_predict_l1_rs = pd.concat([y_p_fam_l1_rs, y_p_gen_l1_rs, y_p_spe_l1_rs], axis=1, sort=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exact Match Score for resampled L1 Penalty:  0.9092172301991662\n",
      "Hamming loss for resampled L1 Penalty:  0.058514744480469325\n"
     ]
    }
   ],
   "source": [
    "hamming_Loss_2 = evaluation_HammingLoss(y_predict_l1_rs, y_test)     \n",
    "exactmatch_Score_2 = evaluation_ExactMatch(y_predict_l1_rs, y_test)\n",
    "print('Exact Match Score for resampled L1 Penalty: ', exactmatch_Score_2)\n",
    "print('Hamming loss for resampled L1 Penalty: ', hamming_Loss_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Hamm Loss</th>\n",
       "      <th>Exact Match Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Gaussian</th>\n",
       "      <td>0.007411</td>\n",
       "      <td>0.989810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l1 Svm</th>\n",
       "      <td>0.059132</td>\n",
       "      <td>0.909217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>resampled l1 svm</th>\n",
       "      <td>0.058515</td>\n",
       "      <td>0.909217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Hamm Loss  Exact Match Score\n",
       "Gaussian           0.007411           0.989810\n",
       "l1 Svm             0.059132           0.909217\n",
       "resampled l1 svm   0.058515           0.909217"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df['Hamm Loss'] = [hamming_Loss, hamming_Loss_1,hamming_Loss_2]\n",
    "df['Exact Match Score'] = [exactmatch_Score, exactmatch_Score_1,exactmatch_Score_2]\n",
    "df.index = ['Gaussian', \"l1 Svm\", 'resampled l1 svm']\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By the look of it it is clearly visible that gaussian svm performs better than l1 penalized svm and resampled l1 penalized svm"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
